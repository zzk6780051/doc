# 开发文档

## 项目概述

小说章节分割工具是一个基于Python的文本处理工具，使用面向对象设计，具备高可扩展性和可维护性。集成了GitHub Actions自动化工作流，实现全自动的章节分割和文件管理。

## 项目结构

```
├── .github/
│   ├── scripts/
│   │     └── fenli.py          # 核心分割脚本
│   └── workflows/
│         └── split-novels.yml  # GitHub Actions 工作流配置
├── 小说名/                     # 每本小说分割后的章节文件夹
│     ├── 第1章 章节标题.txt
│     ├── 第2章 另一个章节.txt
│     ├── ...
│     ├── metadata.txt          # 元数据信息
│     └── split_stats.txt       # 处理统计
├── zip/                        # ZIP压缩包目录
│     └── 小说名.zip            # 自动生成的压缩文件
├── already/                    # 已处理完成的小说原文件
│     └── 小说名.txt
└── README.md
```

## 核心架构

### EnhancedNovelSplitter 类

主要功能类，包含以下核心方法：

#### 初始化方法
```python
def __init__(self, log_file: Optional[str] = None)
```
- 初始化章节识别模式
- 设置日志系统
- 初始化统计信息

#### 核心方法
- `detect_encoding()` - 文件编码检测
- `detect_chapter_pattern()` - 章节模式识别
- `extract_metadata()` - 元数据提取
- `split_novel()` - 主要分割逻辑
- `create_zip_archive()` - 创建ZIP压缩包
- `batch_process_with_progress()` - 批量处理

### 章节识别模式

工具预定义了多种章节识别正则表达式：

```python
self.chapter_patterns = [
    # 中文章节格式
    r'^## 第[零一二三四五六七八九十百千两万千亿\d]+章[\s\S]*$',
    r'^第[零一二三四五六七八九十百千两万千亿\d]+章[\s\S]*$',
    r'^## [上下卷]?第[零一二三四五六七八九十百千两万千亿\d]+[章节回][\s\S]*$',
    r'^第[零一二三四五六七八九十百千\d]+[章节回][\s\S]*$',
    r'^[上下卷]第[零一二三四五六七八九十百千\d]+[章节回][\s\S]*$',
    # 英文章节格式
    r'^Chapter\s+\d+[\s\S]*$',
    r'^CHAPTER\s+\d+[\s\S]*$',
    r'^##\s+Chapter\s+\d+[\s\S]*$',
    # 其他格式
    r'^【第[零一二三四五六七八九十百千\d]+章】[\s\S]*$',
    r'^\[第[零一二三四五六七八九十百千\d]+章\][\s\S]*$',
]
```

### 文件处理流程

1. **编码检测** - 自动识别文件编码格式
2. **模式匹配** - 分析文本选择最佳章节识别模式
3. **元数据提取** - 从文件头部提取标题、作者等信息
4. **章节分割** - 按章节标题分割内容
5. **去重检查** - 基于MD5哈希值避免重复章节
6. **文件生成** - 创建章节文件和统计信息
7. **ZIP打包** - 生成压缩包文件

## 开发环境设置

### 环境要求
- Python 3.6+
- 标准库依赖：re, os, argparse, glob, logging, typing, datetime, hashlib, zipfile, shutil

### 安装和测试
```bash
# 克隆项目
git clone <repository-url>
cd novel-splitter

# 运行测试
python fenli.py -a  # 批量处理测试
python fenli.py sample.txt -o test_output  # 单文件测试
```

## GitHub Actions 工作流

### 触发条件
- `push` 到包含 `.txt` 文件的提交
- 手动触发 (`workflow_dispatch`)

### 工作流程步骤
1. **环境设置** - 检出代码、设置Python环境
2. **目录准备** - 创建必要的输出目录（already/, zip/）
3. **依赖检查** - 验证Python依赖可用性
4. **文件发现** - 查找根目录下的所有txt文件
5. **批量处理** - 对每个文件调用fenli.py进行处理
6. **ZIP文件检查** - 验证压缩包生成情况
7. **清理工作** - 删除临时文件
8. **提交更改** - 自动提交所有生成的文件

### 环境变量配置
需要在GitHub仓库Secrets中配置：
- `GIT_EMAIL` - Git提交邮箱
- `GIT_NAME` - Git提交用户名

## 扩展开发

### 添加新的章节模式

在 `__init__` 方法的 `chapter_patterns` 列表中添加新的正则表达式：

```python
self.chapter_patterns.append(r'^你的新章节模式$')
```

### 修改输出格式

重写 `generate_chapter_filename` 方法来自定义文件名生成逻辑：

```python
def generate_chapter_filename(self, title: str, index: int, metadata: Dict[str, str]) -> str:
    # 自定义文件名格式 - 直接使用章节标题，不添加序号前缀
    clean_title = re.sub(r'^##\s*', '', title)
    clean_title = re.sub(r'[<>:"/\\|?*]', '_', clean_title)
    return f"{clean_title}.txt"
```

### 增强元数据提取

扩展 `extract_metadata` 方法来识别更多元数据类型：

```python
def extract_metadata(self, lines: List[str]) -> Dict[str, str]:
    metadata = super().extract_metadata(lines)
    # 添加新的元数据提取逻辑
    for line in lines[:50]:
        if '出版社' in line:
            metadata['publisher'] = line.strip()
        if 'ISBN' in line:
            metadata['isbn'] = line.strip()
    return metadata
```

## 测试和调试

### 日志系统
工具使用Python标准logging模块，支持：
- 控制台输出
- 文件日志（通过`--log`参数指定）
- 不同日志级别（INFO、WARNING、ERROR）

### 错误处理
- 文件编码检测失败时使用UTF-8回退
- 章节识别失败时尝试备用模式
- 重复内容自动跳过并记录警告
- ZIP压缩失败时继续处理其他文件

## 性能优化

### 内存管理
- 逐行读取大文件，避免内存溢出
- 使用生成器处理大型文件集合

### 处理效率
- 前500行模式检测，避免全文件扫描
- MD5哈希去重，快速识别重复内容
- 并行处理多个文件（GitHub Actions环境）

## 统计信息

工具会收集并报告以下统计信息：
- 总处理文件数
- 成功分割的文件数
- 失败文件数
- 总章节数
- 生成的ZIP文件数

## 贡献指南

### 代码规范
- 使用类型注解（Type Hints）
- 遵循PEP 8编码规范
- 添加详细的文档字符串

### 提交信息
使用约定式提交格式：
- feat: 新功能
- fix: 修复问题
- docs: 文档更新
- refactor: 代码重构

## 故障排除

### 常见问题
1. **编码识别失败** - 检查文件实际编码，手动指定编码参数
2. **章节识别不准确** - 调整正则表达式模式或添加自定义模式
3. **内存不足** - 分块处理大文件，优化读取逻辑
4. **ZIP文件未生成** - 检查目录权限和磁盘空间

### 调试模式
可以通过修改日志级别来启用详细调试：
```python
self.logger.setLevel(logging.DEBUG)
```

## 版本历史

### v1.1.0
- 新增ZIP压缩包自动生成功能
- 优化章节文件名生成逻辑（直接使用章节标题）
- 增强GitHub Actions工作流
- 改进统计信息和日志记录

### v1.0.0
- 基础章节分割功能
- 多格式章节识别
- GitHub Actions自动化
- 批量处理支持
[file content end]

主要更新内容：

1. **README.md 更新**：
   - 增加了ZIP压缩功能的说明
   - 更新了输出结构，包含zip目录
   - 完善了GitHub Actions工作流程描述
   - 在优势特点中增加了ZIP打包功能

2. **开发.md 更新**：
   - 更新项目结构，增加了zip目录说明
   - 在核心架构中增加了create_zip_archive方法
   - 详细描述了文件处理流程，包括ZIP打包步骤
   - 更新了GitHub Actions工作流的具体步骤
   - 增加了统计信息说明
   - 添加了v1.1.0版本历史记录

这些更新确保了文档与实际代码功能的一致性，特别是新增加的ZIP压缩功能和优化后的文件命名逻辑。